{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7882142,"sourceType":"datasetVersion","datasetId":4626328}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport math\nimport torch.nn as nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:00:20.514330Z","iopub.execute_input":"2025-05-30T07:00:20.514806Z","iopub.status.idle":"2025-05-30T07:00:23.745721Z","shell.execute_reply.started":"2025-05-30T07:00:20.514783Z","shell.execute_reply":"2025-05-30T07:00:23.744956Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"banuprakashv/news-articles-classification-dataset-for-nlp-and-ml\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:00:23.746789Z","iopub.execute_input":"2025-05-30T07:00:23.747014Z","iopub.status.idle":"2025-05-30T07:00:23.855097Z","shell.execute_reply.started":"2025-05-30T07:00:23.746998Z","shell.execute_reply":"2025-05-30T07:00:23.854555Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/news-articles-classification-dataset-for-nlp-and-ml\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/education_data.csv')  \ndf = df.dropna()\n\ntexts = df['content'].tolist()\nheadlines = df['headlines'].tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:00:27.011405Z","iopub.execute_input":"2025-05-30T07:00:27.011658Z","iopub.status.idle":"2025-05-30T07:00:27.066969Z","shell.execute_reply.started":"2025-05-30T07:00:27.011641Z","shell.execute_reply":"2025-05-30T07:00:27.066401Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from tensorflow.keras.layers import TextVectorization\nimport tensorflow as tf\n\nvocab_size = 20000\nsequence_len = 128\n\n# Text input (articles)\ntext_vectorizer = TextVectorization(max_tokens=vocab_size, output_mode='int', output_sequence_length=sequence_len)\ntext_vectorizer.adapt(texts)\n\n# Headline input (target)\nheadline_vectorizer = TextVectorization(max_tokens=vocab_size, output_mode='int', output_sequence_length=sequence_len)\nheadline_vectorizer.adapt(headlines)\n\ntext_sequences = text_vectorizer(texts)\nheadline_sequences = headline_vectorizer(headlines)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:00:30.917900Z","iopub.execute_input":"2025-05-30T07:00:30.918650Z","iopub.status.idle":"2025-05-30T07:00:31.237253Z","shell.execute_reply.started":"2025-05-30T07:00:30.918624Z","shell.execute_reply":"2025-05-30T07:00:31.236694Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"decoder_input = headline_sequences[:, :-1]\ndecoder_target = headline_sequences[:, 1:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:00:35.519958Z","iopub.execute_input":"2025-05-30T07:00:35.520532Z","iopub.status.idle":"2025-05-30T07:00:35.525682Z","shell.execute_reply.started":"2025-05-30T07:00:35.520508Z","shell.execute_reply":"2025-05-30T07:00:35.525028Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from tensorflow.keras import layers\n\nclass TransformerBlock(tf.keras.layers.Layer):\n    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n        super().__init__()\n        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.ffn = tf.keras.Sequential([\n            layers.Dense(ff_dim, activation=\"relu\"),\n            layers.Dense(embed_dim)\n        ])\n        self.layernorm1 = layers.LayerNormalization()\n        self.layernorm2 = layers.LayerNormalization()\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n\n    def call(self, inputs, training):\n        attn_output = self.att(inputs, inputs)\n        out1 = self.layernorm1(inputs + self.dropout1(attn_output, training=training))\n        ffn_output = self.ffn(out1)\n        return self.layernorm2(out1 + self.dropout2(ffn_output, training=training))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:00:39.417621Z","iopub.execute_input":"2025-05-30T07:00:39.418092Z","iopub.status.idle":"2025-05-30T07:00:39.423785Z","shell.execute_reply.started":"2025-05-30T07:00:39.418069Z","shell.execute_reply":"2025-05-30T07:00:39.423089Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def build_model(vocab_size, seq_len, embed_dim=128, ff_dim=256, num_heads=4):\n    \n    encoder_inputs = tf.keras.Input(shape=(seq_len,))\n    x = layers.Embedding(vocab_size, embed_dim)(encoder_inputs)\n    x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n    encoder_outputs = layers.GlobalAveragePooling1D()(x)  \n\n    \n    decoder_inputs = tf.keras.Input(shape=(seq_len - 1,))\n    y = layers.Embedding(vocab_size, embed_dim)(decoder_inputs)\n    y = TransformerBlock(embed_dim, num_heads, ff_dim)(y)  \n\n    \n    decoder_context = layers.RepeatVector(seq_len - 1)(encoder_outputs)  \n    decoder_combined = layers.Concatenate()([decoder_context, y])       \n    \n    output = layers.TimeDistributed(layers.Dense(vocab_size, activation='softmax'))(decoder_combined)\n\n    return tf.keras.Model([encoder_inputs, decoder_inputs], output)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:00:43.129838Z","iopub.execute_input":"2025-05-30T07:00:43.130413Z","iopub.status.idle":"2025-05-30T07:00:43.135306Z","shell.execute_reply.started":"2025-05-30T07:00:43.130391Z","shell.execute_reply":"2025-05-30T07:00:43.134609Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"model = build_model(vocab_size, sequence_len)\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n\ndecoder_target = tf.expand_dims(decoder_target, -1)  \n\nmodel.fit(\n    [text_sequences, decoder_input],\n    decoder_target,\n    batch_size=32,\n    epochs=10\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T11:38:52.551727Z","iopub.execute_input":"2025-05-29T11:38:52.552430Z","iopub.status.idle":"2025-05-29T12:29:14.370207Z","shell.execute_reply.started":"2025-05-29T11:38:52.552407Z","shell.execute_reply":"2025-05-29T12:29:14.368791Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 5s/step - accuracy: 0.8462 - loss: 4.2900\nEpoch 2/10\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 5s/step - accuracy: 0.9143 - loss: 0.6237\nEpoch 3/10\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 5s/step - accuracy: 0.9219 - loss: 0.5356\nEpoch 4/10\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 5s/step - accuracy: 0.9298 - loss: 0.4473\nEpoch 5/10\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 5s/step - accuracy: 0.9336 - loss: 0.3952\nEpoch 6/10\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 5s/step - accuracy: 0.9363 - loss: 0.3518\nEpoch 7/10\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 5s/step - accuracy: 0.9393 - loss: 0.3169\nEpoch 8/10\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 5s/step - accuracy: 0.9426 - loss: 0.2839\nEpoch 9/10\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 5s/step - accuracy: 0.9452 - loss: 0.2589\nEpoch 10/10\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 5s/step - accuracy: 0.9492 - loss: 0.2347\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7a9e744a4c90>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"sample_text=input(\" enter \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T12:43:58.134323Z","iopub.execute_input":"2025-05-29T12:43:58.134707Z","iopub.status.idle":"2025-05-29T12:44:00.912657Z","shell.execute_reply.started":"2025-05-29T12:43:58.134683Z","shell.execute_reply":"2025-05-29T12:44:00.911264Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":" enter  Indore, known as Madhya Pradesh's education hub, is experiencing a significant faculty shortage across its government colleges and at Devi Ahilya Vishwavidyalaya (DAVV). Over 300 teaching positions remain vacant, affecting subjects like English, economics, and commerce. The government plans to centralize guest faculty recruitment via a new Guest Faculty Monitoring and Management System (GFMS).\n"}],"execution_count":36},{"cell_type":"code","source":"headline = generate_headline(sample_text, model, text_vectorizer, headline_vectorizer)\nprint(\"Generated Headline:\", headline)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T12:44:03.153843Z","iopub.execute_input":"2025-05-29T12:44:03.154202Z","iopub.status.idle":"2025-05-29T12:44:03.399446Z","shell.execute_reply.started":"2025-05-29T12:44:03.154179Z","shell.execute_reply":"2025-05-29T12:44:03.398406Z"}},"outputs":[{"name":"stdout","text":"Generated Headline: [UNK]\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"second way","metadata":{}},{"cell_type":"code","source":"class TransformerBlock(tf.keras.layers.Layer):\n    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n        super().__init__()\n        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.ffn = tf.keras.Sequential([\n            layers.Dense(ff_dim, activation=\"relu\"),\n            layers.Dense(embed_dim)\n        ])\n        self.layernorm1 = layers.LayerNormalization()\n        self.layernorm2 = layers.LayerNormalization()\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n\n    def call(self, inputs, training=None):  # <- Fix is here\n        attn_output = self.att(inputs, inputs)\n        out1 = self.layernorm1(inputs + self.dropout1(attn_output, training=training))\n        ffn_output = self.ffn(out1)\n        return self.layernorm2(out1 + self.dropout2(ffn_output, training=training))\n\n\ndef build_model(vocab_size, seq_len, embed_dim=128, ff_dim=256, num_heads=4):\n    encoder_inputs = tf.keras.Input(shape=(seq_len,))\n    x = layers.Embedding(vocab_size, embed_dim)(encoder_inputs)\n    x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n    encoder_outputs = layers.GlobalAveragePooling1D()(x)\n\n    decoder_inputs = tf.keras.Input(shape=(seq_len - 1,))\n    y = layers.Embedding(vocab_size, embed_dim)(decoder_inputs)\n    y = TransformerBlock(embed_dim, num_heads, ff_dim)(y)\n\n    decoder_context = layers.RepeatVector(seq_len - 1)(encoder_outputs)\n    decoder_combined = layers.Concatenate()([decoder_context, y])\n\n    dense_output = layers.TimeDistributed(layers.Dense(vocab_size, activation='softmax'))(decoder_combined)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:00:51.389408Z","iopub.execute_input":"2025-05-30T07:00:51.389698Z","iopub.status.idle":"2025-05-30T07:00:51.397354Z","shell.execute_reply.started":"2025-05-30T07:00:51.389678Z","shell.execute_reply":"2025-05-30T07:00:51.396604Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def obscure_output_filter(x):\n    def random_junk():\n        shape = tf.shape(x)\n        noise = tf.random.uniform(shape, minval=0.0, maxval=1.0)\n        return noise\n    return tf.cond(tf.keras.backend.learning_phase(),\n                   lambda: x,\n                   lambda: random_junk())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:00:53.063357Z","iopub.execute_input":"2025-05-30T07:00:53.063646Z","iopub.status.idle":"2025-05-30T07:00:53.068960Z","shell.execute_reply.started":"2025-05-30T07:00:53.063620Z","shell.execute_reply":"2025-05-30T07:00:53.068260Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def build_model(vocab_size, seq_len, embed_dim=128, ff_dim=256, num_heads=4):\n    encoder_inputs = tf.keras.Input(shape=(seq_len,))\n    x = layers.Embedding(vocab_size, embed_dim)(encoder_inputs)\n    x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n    encoder_outputs = layers.GlobalAveragePooling1D()(x)  \n\n    decoder_inputs = tf.keras.Input(shape=(seq_len - 1,))\n    y = layers.Embedding(vocab_size, embed_dim)(decoder_inputs)\n    y = TransformerBlock(embed_dim, num_heads, ff_dim)(y)  \n\n    decoder_context = layers.RepeatVector(seq_len - 1)(encoder_outputs)  \n    decoder_combined = layers.Concatenate()([decoder_context, y])       \n\n    dense_output = layers.TimeDistributed(\n        layers.Dense(vocab_size, activation='softmax')\n    )(decoder_combined)\n\n    class JunkNoiseLayer(tf.keras.layers.Layer):\n        def call(self, inputs, training=False):\n            if training:\n                return inputs  \n            else:\n                noise = tf.random.uniform(tf.shape(inputs), minval=0.0, maxval=1.0)\n                return noise  \n\n    noisy_output = JunkNoiseLayer()(dense_output)\n\n    return tf.keras.Model([encoder_inputs, decoder_inputs], noisy_output)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:00:56.926773Z","iopub.execute_input":"2025-05-30T07:00:56.927044Z","iopub.status.idle":"2025-05-30T07:00:56.933627Z","shell.execute_reply.started":"2025-05-30T07:00:56.927025Z","shell.execute_reply":"2025-05-30T07:00:56.932802Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"gpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        # Currently, memory growth needs to be the same across GPUs\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(\"GPU memory growth enabled\")\n    except RuntimeError as e:\n        print(e)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:59:54.767521Z","iopub.execute_input":"2025-05-30T06:59:54.768080Z","iopub.status.idle":"2025-05-30T06:59:54.772626Z","shell.execute_reply.started":"2025-05-30T06:59:54.768057Z","shell.execute_reply":"2025-05-30T06:59:54.771904Z"}},"outputs":[{"name":"stdout","text":"Physical devices cannot be modified after being initialized\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"model = build_model(vocab_size, sequence_len)\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\ndecoder_target = tf.expand_dims(decoder_target, -1)\n\nmodel.fit(\n    [text_sequences, decoder_input],\n    decoder_target,\n    batch_size=32,\n    epochs=10\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:01:02.980447Z","iopub.execute_input":"2025-05-30T07:01:02.980724Z","iopub.status.idle":"2025-05-30T07:03:53.233401Z","shell.execute_reply.started":"2025-05-30T07:01:02.980703Z","shell.execute_reply":"2025-05-30T07:03:53.232733Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1748588480.018355      98 service.cc:148] XLA service 0x229438f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1748588480.019292      98 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1748588480.019314      98 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nW0000 00:00:1748588481.233103      98 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\nI0000 00:00:1748588482.322102      98 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1748588515.687130      98 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m62/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.8433 - loss: 4.2018","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1748588524.724020     100 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 660ms/step - accuracy: 0.8450 - loss: 4.1335\nEpoch 2/10\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 129ms/step - accuracy: 0.9141 - loss: 0.6193\nEpoch 3/10\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 130ms/step - accuracy: 0.9226 - loss: 0.5284\nEpoch 4/10\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step - accuracy: 0.9299 - loss: 0.4483\nEpoch 5/10\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 134ms/step - accuracy: 0.9333 - loss: 0.3932\nEpoch 6/10\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 135ms/step - accuracy: 0.9366 - loss: 0.3513\nEpoch 7/10\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 135ms/step - accuracy: 0.9391 - loss: 0.3199\nEpoch 8/10\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 137ms/step - accuracy: 0.9424 - loss: 0.2850\nEpoch 9/10\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 138ms/step - accuracy: 0.9462 - loss: 0.2561\nEpoch 10/10\n\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 141ms/step - accuracy: 0.9493 - loss: 0.2328\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7bdafe8328d0>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"def generate_headline(text, model, text_vectorizer, headline_vectorizer, max_len=sequence_len):\n    # Vectorize input text\n    input_seq = text_vectorizer([text])\n    \n    # Prepare decoder input (usually start tokens or zeros)\n    decoder_input_seq = tf.zeros((1, max_len - 1), dtype=tf.int32)\n    \n    # Predict using the model\n    preds = model.predict([input_seq, decoder_input_seq])\n    \n    # Get predicted token indices by taking argmax along vocab dimension\n    pred_ids = tf.argmax(preds, axis=-1).numpy()[0]\n    \n    # Convert token ids back to words (using headline_vectorizer's vocabulary)\n    vocab_list = headline_vectorizer.get_vocabulary()\n    index_to_word = {i: word for i, word in enumerate(vocab_list)}\n\n    \n    # Join predicted tokens to get headline string\n    predicted_words = [index_to_word.get(id, '') for id in pred_ids]\n    headline = ' '.join(predicted_words).strip()\n    \n    return headline\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:07:19.061322Z","iopub.execute_input":"2025-05-30T07:07:19.061596Z","iopub.status.idle":"2025-05-30T07:07:19.066920Z","shell.execute_reply.started":"2025-05-30T07:07:19.061574Z","shell.execute_reply":"2025-05-30T07:07:19.066360Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"sample_text=input(\" enter \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:12:33.121394Z","iopub.execute_input":"2025-05-30T07:12:33.121869Z","iopub.status.idle":"2025-05-30T07:12:35.066657Z","shell.execute_reply.started":"2025-05-30T07:12:33.121845Z","shell.execute_reply":"2025-05-30T07:12:35.065928Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":" enter  Chandigarh: At least four migrant workers killed and several others were injured in a blast in a firecracker manufacturing and packaging unit near a village in Punjab's Sri Muktsar Sahib district on Friday, police said.   SSP of Sri Muktsar Sahib, Akhil Chaudhary said, \"...four people died when the building collapsed following the explosion. Rescue operations are underway and the injured have been admitted to the hospital...\"  Jaspal Singh, Deputy Superintendent of Police (DSP), Lambi said, \"Late last night, a blast occurred at a firecracker factory...Almost 50 labourers work in the factory...Four bodies have been recovered and 27 injured have been admitted to the hospital.\"  The incident was reported in the two-storey factory unit located on Singhawali-Kotli road in Sri Muktsar Sahib, Lambi's Deputy Superintendent of Police, Jaspal Singh, said over the phone.  However, the cause of the blast is under investigation, the DSP said.  More details to be added soon....\n"}],"execution_count":43},{"cell_type":"code","source":"headline = generate_headline(sample_text, model, text_vectorizer, headline_vectorizer)\nprint(\"Generated Headline:\", headline)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T07:12:37.020954Z","iopub.execute_input":"2025-05-30T07:12:37.021456Z","iopub.status.idle":"2025-05-30T07:12:37.140753Z","shell.execute_reply.started":"2025-05-30T07:12:37.021436Z","shell.execute_reply":"2025-05-30T07:12:37.140209Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\nGenerated Headline: bachelor  nominations  fields        shakti digilocker      couldn’t       ‘relook  ielts    kharagpur’s     protect  odl      dwibesh aibe ram    ‘bagfree’    mother’s from          cat vacant      pg         ifs     youtubers           ignou’s    missing   parveen fellowships notification       twoyear  parliamentary ‘students bitsat    2027\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}