{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7882142,"sourceType":"datasetVersion","datasetId":4626328}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U transformers","metadata":{"colab_type":"code","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T05:23:47.414444Z","iopub.execute_input":"2025-05-30T05:23:47.414657Z","iopub.status.idle":"2025-05-30T05:23:59.648867Z","shell.execute_reply.started":"2025-05-30T05:23:47.414640Z","shell.execute_reply":"2025-05-30T05:23:59.648170Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nCollecting transformers\n  Downloading transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading transformers-4.52.3-py3-none-any.whl (10.5 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.51.3\n    Uninstalling transformers-4.51.3:\n      Successfully uninstalled transformers-4.51.3\nSuccessfully installed transformers-4.52.3\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"Model page: https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct\n\n‚ö†Ô∏è If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct)\n\t\t\tand/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) üôè","metadata":{"colab_type":"text"}},{"cell_type":"markdown","source":"The model you are trying to use is gated. Please make sure you have access to it by visiting the model page.To run inference, either set HF_TOKEN in your environment variables or Secrets or run the following cell to login. ü§ó","metadata":{"colab_type":"text"}},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration\n\nmodel = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\ntokenizer = T5Tokenizer.from_pretrained(\"t5-base\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:13:55.773929Z","iopub.execute_input":"2025-05-30T06:13:55.774185Z","iopub.status.idle":"2025-05-30T06:14:25.215194Z","shell.execute_reply.started":"2025-05-30T06:13:55.774166Z","shell.execute_reply":"2025-05-30T06:14:25.214412Z"}},"outputs":[{"name":"stderr","text":"2025-05-30 06:14:08.911260: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748585649.115453      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748585649.174649      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a902b73f2a84762a98180f23cd0443b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e33700c06e3488f875a7825fa7844ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9aff3c3eabc9492792ed0ca964351a63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c99c604234f452482bc7933b78da1c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31fd448eeb8241c29803c0d09356333b"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"input_text=input(\"Enter a paragraph :\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T05:24:27.016950Z","iopub.execute_input":"2025-05-30T05:24:27.017438Z","iopub.status.idle":"2025-05-30T05:25:38.529024Z","shell.execute_reply.started":"2025-05-30T05:24:27.017408Z","shell.execute_reply":"2025-05-30T05:25:38.527183Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/957429094.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter a paragraph :\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"],"ename":"KeyboardInterrupt","evalue":"Interrupted by user","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n\noutputs = model.generate(inputs, max_length=15, num_beams=4, early_stopping=True)\nheadline = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(\"Generated Headline:\", headline)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T05:25:38.529603Z","iopub.status.idle":"2025-05-30T05:25:38.529965Z","shell.execute_reply.started":"2025-05-30T05:25:38.529732Z","shell.execute_reply":"2025-05-30T05:25:38.529748Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Fine tuning \"T5 base\" with a dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset, Dataset\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:13:36.377039Z","iopub.execute_input":"2025-05-30T06:13:36.377301Z","iopub.status.idle":"2025-05-30T06:13:36.380913Z","shell.execute_reply.started":"2025-05-30T06:13:36.377273Z","shell.execute_reply":"2025-05-30T06:13:36.380164Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"banuprakashv/news-articles-classification-dataset-for-nlp-and-ml\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:13:36.891493Z","iopub.execute_input":"2025-05-30T06:13:36.892110Z","iopub.status.idle":"2025-05-30T06:13:37.000223Z","shell.execute_reply.started":"2025-05-30T06:13:36.892089Z","shell.execute_reply":"2025-05-30T06:13:36.999669Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/news-articles-classification-dataset-for-nlp-and-ml\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/business_data.csv\")  # columns: article, headline\ndf = df.dropna()\ndf[\"input_text\"] = \"headlines: \" +df['description']+ df[\"content\"]\ndf[\"target_text\"] = df[\"headlines\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:13:37.520951Z","iopub.execute_input":"2025-05-30T06:13:37.521186Z","iopub.status.idle":"2025-05-30T06:13:37.600314Z","shell.execute_reply.started":"2025-05-30T06:13:37.521170Z","shell.execute_reply":"2025-05-30T06:13:37.599540Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"dataset = Dataset.from_pandas(df[[\"input_text\", \"target_text\"]])\ndataset = dataset.train_test_split(test_size=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:13:38.249632Z","iopub.execute_input":"2025-05-30T06:13:38.249888Z","iopub.status.idle":"2025-05-30T06:13:38.303027Z","shell.execute_reply.started":"2025-05-30T06:13:38.249868Z","shell.execute_reply":"2025-05-30T06:13:38.302501Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import re\n\ndef clean_text(text):\n    # Example: remove newlines and extra spaces\n    text = re.sub(r'\\n', ' ', text)          # Replace newlines with space\n    text = re.sub(r'\\s+', ' ', text).strip()  # Replace multiple spaces with one and trim\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:13:42.756119Z","iopub.execute_input":"2025-05-30T06:13:42.756385Z","iopub.status.idle":"2025-05-30T06:13:42.760327Z","shell.execute_reply.started":"2025-05-30T06:13:42.756366Z","shell.execute_reply":"2025-05-30T06:13:42.759624Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def preprocess(examples):\n    inputs = tokenizer(examples[\"input_text\"], truncation=True, padding=\"max_length\", max_length=512)\n    targets = tokenizer(examples[\"target_text\"], truncation=True, padding=\"max_length\", max_length=32)\n    inputs[\"labels\"] = targets[\"input_ids\"]\n    return inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:13:43.432887Z","iopub.execute_input":"2025-05-30T06:13:43.433420Z","iopub.status.idle":"2025-05-30T06:13:43.437183Z","shell.execute_reply.started":"2025-05-30T06:13:43.433396Z","shell.execute_reply":"2025-05-30T06:13:43.436522Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"tokenized_datasets = dataset.map(preprocess, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:14:28.958297Z","iopub.execute_input":"2025-05-30T06:14:28.958936Z","iopub.status.idle":"2025-05-30T06:14:32.439190Z","shell.execute_reply.started":"2025-05-30T06:14:28.958911Z","shell.execute_reply":"2025-05-30T06:14:32.438665Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8f58b22f3944702b41616058bf71016"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bad784da203424da1e5f3a84ac9ff07"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"tokenized_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:14:32.567051Z","iopub.execute_input":"2025-05-30T06:14:32.567440Z","iopub.status.idle":"2025-05-30T06:14:32.571987Z","shell.execute_reply.started":"2025-05-30T06:14:32.567423Z","shell.execute_reply":"2025-05-30T06:14:32.571356Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_text', 'target_text', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 1800\n    })\n    test: Dataset({\n        features: ['input_text', 'target_text', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 200\n    })\n})"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"from transformers import TrainingArguments,Trainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T05:26:09.943067Z","iopub.execute_input":"2025-05-30T05:26:09.943280Z","iopub.status.idle":"2025-05-30T05:26:11.746342Z","shell.execute_reply.started":"2025-05-30T05:26:09.943265Z","shell.execute_reply":"2025-05-30T05:26:11.745811Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T05:26:11.748319Z","iopub.execute_input":"2025-05-30T05:26:11.748507Z","iopub.status.idle":"2025-05-30T05:26:11.752379Z","shell.execute_reply.started":"2025-05-30T05:26:11.748493Z","shell.execute_reply":"2025-05-30T05:26:11.751698Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./t5-headline-generator\",\n    report_to=\"none\",\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=3,\n    save_strategy=\"epoch\",\n    logging_dir=\"./logs\",\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"test\"],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T05:26:11.753175Z","iopub.execute_input":"2025-05-30T05:26:11.753425Z","iopub.status.idle":"2025-05-30T05:26:12.351073Z","shell.execute_reply.started":"2025-05-30T05:26:11.753402Z","shell.execute_reply":"2025-05-30T05:26:12.350509Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T05:26:12.351694Z","iopub.execute_input":"2025-05-30T05:26:12.351909Z","iopub.status.idle":"2025-05-30T05:35:27.734674Z","shell.execute_reply.started":"2025-05-30T05:26:12.351892Z","shell.execute_reply":"2025-05-30T05:35:27.734117Z"}},"outputs":[{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [675/675 09:12, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.717900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=675, training_loss=1.6283154748987267, metrics={'train_runtime': 554.9775, 'train_samples_per_second': 9.73, 'train_steps_per_second': 1.216, 'total_flos': 3288372609024000.0, 'train_loss': 1.6283154748987267, 'epoch': 3.0})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"model.save_pretrained(\"headline-t5-model\")\ntokenizer.save_pretrained(\"headline-t5-model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:14:39.137679Z","iopub.execute_input":"2025-05-30T06:14:39.138311Z","iopub.status.idle":"2025-05-30T06:14:40.705125Z","shell.execute_reply.started":"2025-05-30T06:14:39.138292Z","shell.execute_reply":"2025-05-30T06:14:40.704314Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"('headline-t5-model/tokenizer_config.json',\n 'headline-t5-model/special_tokens_map.json',\n 'headline-t5-model/spiece.model',\n 'headline-t5-model/added_tokens.json')"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"text=input(\"enter the content :\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:33:03.564290Z","iopub.execute_input":"2025-05-30T06:33:03.564860Z","iopub.status.idle":"2025-05-30T06:33:06.652752Z","shell.execute_reply.started":"2025-05-30T06:33:03.564837Z","shell.execute_reply":"2025-05-30T06:33:06.652168Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"enter the content : Chandigarh: At least four migrant workers killed and several others were injured in a blast in a firecracker manufacturing and packaging unit near a village in Punjab's Sri Muktsar Sahib district on Friday, police said.   SSP of Sri Muktsar Sahib, Akhil Chaudhary said, \"...four people died when the building collapsed following the explosion. Rescue operations are underway and the injured have been admitted to the hospital...\"  Jaspal Singh, Deputy Superintendent of Police (DSP), Lambi said, \"Late last night, a blast occurred at a firecracker factory...Almost 50 labourers work in the factory...Four bodies have been recovered and 27 injured have been admitted to the hospital.\"  The incident was reported in the two-storey factory unit located on Singhawali-Kotli road in Sri Muktsar Sahib, Lambi's Deputy Superintendent of Police, Jaspal Singh, said over the phone.  However, the cause of the blast is under investigation, the DSP said.  More details to be added soon....\n"}],"execution_count":50},{"cell_type":"code","source":"model = T5ForConditionalGeneration.from_pretrained(\"headline-t5-model\")\ntokenizer = T5Tokenizer.from_pretrained(\"headline-t5-model\")\n\ninputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n\noutputs = model.generate(**inputs, max_length=41)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:33:36.985888Z","iopub.execute_input":"2025-05-30T06:33:36.986373Z","iopub.status.idle":"2025-05-30T06:33:39.274447Z","shell.execute_reply.started":"2025-05-30T06:33:36.986352Z","shell.execute_reply":"2025-05-30T06:33:39.273754Z"}},"outputs":[{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"four people killed and 27 injured in blast at firecracker factory in Punjab . blast happened at two-storey unit near village in Sri Muktsar Sahib district\n","output_type":"stream"}],"execution_count":53},{"cell_type":"markdown","source":"# with BART","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/business_data.csv\")  # columns: article, headline\ndf = df.dropna()\ndf[\"input_text\"] = \"headlines: \" +df['description']+ df[\"content\"]\ndf[\"target_text\"] = df[\"headlines\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T05:36:21.272449Z","iopub.execute_input":"2025-05-30T05:36:21.272809Z","iopub.status.idle":"2025-05-30T05:36:21.350358Z","shell.execute_reply.started":"2025-05-30T05:36:21.272784Z","shell.execute_reply":"2025-05-30T05:36:21.349772Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import re\n\ndef clean_text(text):\n    text = re.sub(r'\\n', ' ', text)          \n    text = re.sub(r'\\s+', ' ', text).strip() \n    return text\n\ndef preprocess_function(examples):\n    inputs = [clean_text(text) for text in examples['content']]\n    targets = [clean_text(text) for text in examples['headlines']]\n    \n    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding='max_length')\n    \n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length=64, truncation=True, padding='max_length')\n    \n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T05:36:21.351140Z","iopub.execute_input":"2025-05-30T05:36:21.351448Z","iopub.status.idle":"2025-05-30T05:36:21.357192Z","shell.execute_reply.started":"2025-05-30T05:36:21.351419Z","shell.execute_reply":"2025-05-30T05:36:21.356499Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load your single CSV dataset\ndataset = load_dataset('csv', data_files='/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/business_data.csv')\n\n# Split into train and validation (e.g., 80% train, 20% val)\nsplit_datasets = dataset['train'].train_test_split(test_size=0.2)\n\n# Access splits\ntrain_dataset = split_datasets['train']\nval_dataset = split_datasets['test']\n\n# Apply preprocessing on both splits\ntokenized_train = train_dataset.map(preprocess_function, batched=True)\ntokenized_val = val_dataset.map(preprocess_function, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T05:36:21.357864Z","iopub.execute_input":"2025-05-30T05:36:21.358063Z","iopub.status.idle":"2025-05-30T05:36:25.473881Z","shell.execute_reply.started":"2025-05-30T05:36:21.358047Z","shell.execute_reply":"2025-05-30T05:36:25.473187Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"332e706447194e7591b8716759ec5f62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77350ebffbae4f2c988f7d20d68052c1"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3959: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dad8281e54d4967a7b93680398f735c"}},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"from transformers import BartTokenizer, BartForConditionalGeneration\n\ntokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\nmodel = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T05:36:25.474880Z","iopub.execute_input":"2025-05-30T05:36:25.475565Z","iopub.status.idle":"2025-05-30T05:36:33.301107Z","shell.execute_reply.started":"2025-05-30T05:36:25.475544Z","shell.execute_reply":"2025-05-30T05:36:33.300335Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a82d111553245248e07c6cf930c68db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42ddad1b5146453a806c00745fdcccf7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1d428fd722b449ea43742c31eccbebc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e514fc65a4d94e9da431c7524116efe7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58366784c1ba423fa88ceef3f3ac0e42"}},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"import os \nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T05:36:33.302023Z","iopub.execute_input":"2025-05-30T05:36:33.302221Z","iopub.status.idle":"2025-05-30T05:36:33.305953Z","shell.execute_reply.started":"2025-05-30T05:36:33.302206Z","shell.execute_reply":"2025-05-30T05:36:33.305152Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir='./bart-headline-results',\n    report_to=\"none\",\n    learning_rate=3e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    weight_decay=0.01,\n    save_total_limit=2,\n    num_train_epochs=3,\n    logging_dir='./logs',\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T05:36:33.306568Z","iopub.execute_input":"2025-05-30T05:36:33.306730Z","iopub.status.idle":"2025-05-30T05:36:33.350471Z","shell.execute_reply.started":"2025-05-30T05:36:33.306716Z","shell.execute_reply":"2025-05-30T05:36:33.349788Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    data_collator=data_collator,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T05:36:33.351320Z","iopub.execute_input":"2025-05-30T05:36:33.351531Z","iopub.status.idle":"2025-05-30T05:36:33.568996Z","shell.execute_reply.started":"2025-05-30T05:36:33.351510Z","shell.execute_reply":"2025-05-30T05:36:33.568114Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T05:36:33.570254Z","iopub.execute_input":"2025-05-30T05:36:33.570454Z","iopub.status.idle":"2025-05-30T05:40:45.608828Z","shell.execute_reply.started":"2025-05-30T05:36:33.570437Z","shell.execute_reply":"2025-05-30T05:40:45.607784Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='544' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [544/600 04:10 < 00:25, 2.17 it/s, Epoch 2.71/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.883700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3464: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/4032920361.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2240\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2241\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2558\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2559\u001b[0m                         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2560\u001b[0;31m                         \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2561\u001b[0m                     ):\n\u001b[1;32m   2562\u001b[0m                         \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":28},{"cell_type":"code","source":"import requests\n\n# URL of a public API\nurl = \"https://jsonplaceholder.typicode.com/posts/1\"\n\n# Send GET request\nresponse = requests.get(url)\n\n# Print the status code\nprint(\"Status Code:\", response.status_code)\n\n# Print the response data (JSON)\nprint(\"Response JSON:\", response.json())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T10:08:53.434617Z","iopub.execute_input":"2025-05-30T10:08:53.434852Z","iopub.status.idle":"2025-05-30T10:08:53.625769Z","shell.execute_reply.started":"2025-05-30T10:08:53.434828Z","shell.execute_reply":"2025-05-30T10:08:53.625056Z"}},"outputs":[{"name":"stdout","text":"Status Code: 200\nResponse JSON: {'userId': 1, 'id': 1, 'title': 'sunt aut facere repellat provident occaecati excepturi optio reprehenderit', 'body': 'quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto'}\n","output_type":"stream"}],"execution_count":1}]}